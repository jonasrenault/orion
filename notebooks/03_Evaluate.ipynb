{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35388cc5-0837-4684-b8bc-6bb966702905",
   "metadata": {},
   "source": [
    "# Evaluate military vehicle detections on The Search_2 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3f1a4-6411-42c5-97f9-6edf5f6da5ab",
   "metadata": {},
   "source": [
    "This notebook provides a small benchmark to evaluate automated target recognition of military vehicles on a real dataset. Deep-learning object detection models can give reasonable detection performance when fine-tuned on specific datasets. However, acquiring enough data corresponding to a real military setting is a challenge, as demonstrated by this project. It is therefore important to evaluate these models in a military setting, with a target area around tens of pixels in a cluttered environment.\n",
    "\n",
    "We propose to use [The Search_2](https://figshare.com/articles/dataset/The_Search_2_dataset/1041463) dataset for such an evaluation. The Search_2 dataset consists of 44 high-resolution digital color images of different complex natural scenes, with each scene (image) containing a single military vehicle that serves as a search target. Ground truth annotations are provided for the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8b01e-bb87-478f-9d48-3a57dd97d7a5",
   "metadata": {},
   "source": [
    "### Download and load the dataset\n",
    "\n",
    "To begin, we download the dataset and load it into fiftyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c99ff-30fe-4767-80de-3a33f22d6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion.config.settings import settings\n",
    "from orion.datasets.search2 import download, load_search_2_dataset\n",
    "\n",
    "search_2_dir = settings.ORION_HOME_DIR / \"search_2\"\n",
    "download(search_2_dir)\n",
    "dataset = load_search_2_dataset(search_2_dir / \"search_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3db716-8dac-49c2-8007-0a5e4ca63ee4",
   "metadata": {},
   "source": [
    "We map the labels which identify each target in the dataset to the four classes with which our model was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620fa14-ee55-47f1-8272-4e95cb00a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion.datasets.search2 import LABEL_MAPPING\n",
    "\n",
    "dataset.map_labels(\"ground_truth\", LABEL_MAPPING).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49195965-d636-49a8-ab3f-81048db9ef31",
   "metadata": {},
   "source": [
    "### Evaluate a pretrained model on this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e75812-b124-4400-b226-b69af250aca1",
   "metadata": {},
   "source": [
    "Once our test dataset is ready, we can evaluate a pretrained model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26371904-2670-4278-aac0-7f630870799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from orion.yolo.yolo import predict\n",
    "\n",
    "model = Path.cwd().parent / \"resources/models/orion12n.pt\"\n",
    "results_predict = predict(model, data=search_2_dir / \"search_2/images\")\n",
    "\n",
    "# Load the path of the prediction model results\n",
    "results_predict_dir = Path(results_predict[0].save_dir) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1158acce-3a7f-4760-93fe-373e111a851a",
   "metadata": {},
   "source": [
    "Let's load the model's predictions into our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b9a5f-5c61-4a8e-9110-235e1b25319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from orion.yolo.utils import add_yolo_detections\n",
    "\n",
    "prediction_field = \"yolo12\"\n",
    "predictions_dir = results_predict_dir / \"labels\"\n",
    "add_yolo_detections(\n",
    "    dataset,\n",
    "    prediction_field=prediction_field,\n",
    "    predictions_dir=predictions_dir,\n",
    "    class_list=[\"AFV\", \"APC\", \"MEV\", \"LAV\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c91d2-735b-4381-9ab7-b4fd99301df7",
   "metadata": {},
   "source": [
    "Once that's done, we can evaluate our model's predictions and print the mean Average Precision (mAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06db9a0-45b8-4c9f-9234-cc0622ea630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_results = dataset.evaluate_detections(\n",
    "    prediction_field,\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    "    gt_field=\"ground_truth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165cb92-feb7-45b8-848c-5eeb78555506",
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = detection_results.mAP()\n",
    "print(f\"mAP = {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78805538-57af-4949-bf34-81fb29146b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_results.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d924b9-ca18-4aa1-855d-a6d1523f92fe",
   "metadata": {},
   "source": [
    "We don't have a lot of test images, but our scores aren't good anyways... It's maybe easier to visualize the results in fiftyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805b0a1-d13b-48a1-bae1-53085f3b7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "session.open_tab()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
